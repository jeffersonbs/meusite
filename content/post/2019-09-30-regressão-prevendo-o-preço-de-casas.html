---
title: 'Regressão: predição do preço de casas'
author: Jefferson Barbosa
date: '2019-09-30'
slug: regressão-predição-do-preço-de-casas
categories: []
tags:
  - regression
  - random forest
  - gradient boosting
  - vector machines
---  



<h2>
Sobre os dados
</h2>
<p>Os dados utilizados aqui são provenientes da competição do <a href="kaggle.com">Kaggle</a> chamada de <a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview">House prices: Advanced Regression Techniques</a>. O conjunto de dados contêm 80 variáveis explicativas sobre algumas casas em Ames/Iowa e o objetivo é o de predizer o valor de venda dessas casas.</p>
<p>Nesta publicação eu mostrarei o passo a passo da minha análise, mostrado a forma como eu limpei os dados, o feature engineering e a modelagem. Vou fazer três modelos e um ensemble, utilizando random forest, stochastic gradient boosting e support vector machines com kernel radial. Os pesos do ensemble serão estimados utilizando um modelo linear e compararei o desempenho dos modelos utilizando o RMSE.</p>
<h2>
Processamento dos dados
</h2>
<p>Nesta etapa eu utilizarei os seguintes pacotes:</p>
<pre class="r"><code>library(dplyr)
library(naniar)
library(corrplot)
library(ggplot2)
library(randomForest)</code></pre>
<p>O conjunto de dados conta com 1460 observações e 80 variáveis explicativas.</p>
<pre class="r"><code>str(dados)</code></pre>
<pre><code>## &#39;data.frame&#39;:    1460 obs. of  81 variables:
##  $ Id           : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ MSSubClass   : int  60 20 60 70 60 50 20 60 50 190 ...
##  $ MSZoning     : chr  &quot;RL&quot; &quot;RL&quot; &quot;RL&quot; &quot;RL&quot; ...
##  $ LotFrontage  : int  65 80 68 60 84 85 75 NA 51 50 ...
##  $ LotArea      : int  8450 9600 11250 9550 14260 14115 10084 10382 6120 7420 ...
##  $ Street       : chr  &quot;Pave&quot; &quot;Pave&quot; &quot;Pave&quot; &quot;Pave&quot; ...
##  $ Alley        : chr  NA NA NA NA ...
##  $ LotShape     : chr  &quot;Reg&quot; &quot;Reg&quot; &quot;IR1&quot; &quot;IR1&quot; ...
##  $ LandContour  : chr  &quot;Lvl&quot; &quot;Lvl&quot; &quot;Lvl&quot; &quot;Lvl&quot; ...
##  $ Utilities    : chr  &quot;AllPub&quot; &quot;AllPub&quot; &quot;AllPub&quot; &quot;AllPub&quot; ...
##  $ LotConfig    : chr  &quot;Inside&quot; &quot;FR2&quot; &quot;Inside&quot; &quot;Corner&quot; ...
##  $ LandSlope    : chr  &quot;Gtl&quot; &quot;Gtl&quot; &quot;Gtl&quot; &quot;Gtl&quot; ...
##  $ Neighborhood : chr  &quot;CollgCr&quot; &quot;Veenker&quot; &quot;CollgCr&quot; &quot;Crawfor&quot; ...
##  $ Condition1   : chr  &quot;Norm&quot; &quot;Feedr&quot; &quot;Norm&quot; &quot;Norm&quot; ...
##  $ Condition2   : chr  &quot;Norm&quot; &quot;Norm&quot; &quot;Norm&quot; &quot;Norm&quot; ...
##  $ BldgType     : chr  &quot;1Fam&quot; &quot;1Fam&quot; &quot;1Fam&quot; &quot;1Fam&quot; ...
##  $ HouseStyle   : chr  &quot;2Story&quot; &quot;1Story&quot; &quot;2Story&quot; &quot;2Story&quot; ...
##  $ OverallQual  : int  7 6 7 7 8 5 8 7 7 5 ...
##  $ OverallCond  : int  5 8 5 5 5 5 5 6 5 6 ...
##  $ YearBuilt    : int  2003 1976 2001 1915 2000 1993 2004 1973 1931 1939 ...
##  $ YearRemodAdd : int  2003 1976 2002 1970 2000 1995 2005 1973 1950 1950 ...
##  $ RoofStyle    : chr  &quot;Gable&quot; &quot;Gable&quot; &quot;Gable&quot; &quot;Gable&quot; ...
##  $ RoofMatl     : chr  &quot;CompShg&quot; &quot;CompShg&quot; &quot;CompShg&quot; &quot;CompShg&quot; ...
##  $ Exterior1st  : chr  &quot;VinylSd&quot; &quot;MetalSd&quot; &quot;VinylSd&quot; &quot;Wd Sdng&quot; ...
##  $ Exterior2nd  : chr  &quot;VinylSd&quot; &quot;MetalSd&quot; &quot;VinylSd&quot; &quot;Wd Shng&quot; ...
##  $ MasVnrType   : chr  &quot;BrkFace&quot; &quot;None&quot; &quot;BrkFace&quot; &quot;None&quot; ...
##  $ MasVnrArea   : int  196 0 162 0 350 0 186 240 0 0 ...
##  $ ExterQual    : chr  &quot;Gd&quot; &quot;TA&quot; &quot;Gd&quot; &quot;TA&quot; ...
##  $ ExterCond    : chr  &quot;TA&quot; &quot;TA&quot; &quot;TA&quot; &quot;TA&quot; ...
##  $ Foundation   : chr  &quot;PConc&quot; &quot;CBlock&quot; &quot;PConc&quot; &quot;BrkTil&quot; ...
##  $ BsmtQual     : chr  &quot;Gd&quot; &quot;Gd&quot; &quot;Gd&quot; &quot;TA&quot; ...
##  $ BsmtCond     : chr  &quot;TA&quot; &quot;TA&quot; &quot;TA&quot; &quot;Gd&quot; ...
##  $ BsmtExposure : chr  &quot;No&quot; &quot;Gd&quot; &quot;Mn&quot; &quot;No&quot; ...
##  $ BsmtFinType1 : chr  &quot;GLQ&quot; &quot;ALQ&quot; &quot;GLQ&quot; &quot;ALQ&quot; ...
##  $ BsmtFinSF1   : int  706 978 486 216 655 732 1369 859 0 851 ...
##  $ BsmtFinType2 : chr  &quot;Unf&quot; &quot;Unf&quot; &quot;Unf&quot; &quot;Unf&quot; ...
##  $ BsmtFinSF2   : int  0 0 0 0 0 0 0 32 0 0 ...
##  $ BsmtUnfSF    : int  150 284 434 540 490 64 317 216 952 140 ...
##  $ TotalBsmtSF  : int  856 1262 920 756 1145 796 1686 1107 952 991 ...
##  $ Heating      : chr  &quot;GasA&quot; &quot;GasA&quot; &quot;GasA&quot; &quot;GasA&quot; ...
##  $ HeatingQC    : chr  &quot;Ex&quot; &quot;Ex&quot; &quot;Ex&quot; &quot;Gd&quot; ...
##  $ CentralAir   : chr  &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; ...
##  $ Electrical   : chr  &quot;SBrkr&quot; &quot;SBrkr&quot; &quot;SBrkr&quot; &quot;SBrkr&quot; ...
##  $ X1stFlrSF    : int  856 1262 920 961 1145 796 1694 1107 1022 1077 ...
##  $ X2ndFlrSF    : int  854 0 866 756 1053 566 0 983 752 0 ...
##  $ LowQualFinSF : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ GrLivArea    : int  1710 1262 1786 1717 2198 1362 1694 2090 1774 1077 ...
##  $ BsmtFullBath : int  1 0 1 1 1 1 1 1 0 1 ...
##  $ BsmtHalfBath : int  0 1 0 0 0 0 0 0 0 0 ...
##  $ FullBath     : int  2 2 2 1 2 1 2 2 2 1 ...
##  $ HalfBath     : int  1 0 1 0 1 1 0 1 0 0 ...
##  $ BedroomAbvGr : int  3 3 3 3 4 1 3 3 2 2 ...
##  $ KitchenAbvGr : int  1 1 1 1 1 1 1 1 2 2 ...
##  $ KitchenQual  : chr  &quot;Gd&quot; &quot;TA&quot; &quot;Gd&quot; &quot;Gd&quot; ...
##  $ TotRmsAbvGrd : int  8 6 6 7 9 5 7 7 8 5 ...
##  $ Functional   : chr  &quot;Typ&quot; &quot;Typ&quot; &quot;Typ&quot; &quot;Typ&quot; ...
##  $ Fireplaces   : int  0 1 1 1 1 0 1 2 2 2 ...
##  $ FireplaceQu  : chr  NA &quot;TA&quot; &quot;TA&quot; &quot;Gd&quot; ...
##  $ GarageType   : chr  &quot;Attchd&quot; &quot;Attchd&quot; &quot;Attchd&quot; &quot;Detchd&quot; ...
##  $ GarageYrBlt  : int  2003 1976 2001 1998 2000 1993 2004 1973 1931 1939 ...
##  $ GarageFinish : chr  &quot;RFn&quot; &quot;RFn&quot; &quot;RFn&quot; &quot;Unf&quot; ...
##  $ GarageCars   : int  2 2 2 3 3 2 2 2 2 1 ...
##  $ GarageArea   : int  548 460 608 642 836 480 636 484 468 205 ...
##  $ GarageQual   : chr  &quot;TA&quot; &quot;TA&quot; &quot;TA&quot; &quot;TA&quot; ...
##  $ GarageCond   : chr  &quot;TA&quot; &quot;TA&quot; &quot;TA&quot; &quot;TA&quot; ...
##  $ PavedDrive   : chr  &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; ...
##  $ WoodDeckSF   : int  0 298 0 0 192 40 255 235 90 0 ...
##  $ OpenPorchSF  : int  61 0 42 35 84 30 57 204 0 4 ...
##  $ EnclosedPorch: int  0 0 0 272 0 0 0 228 205 0 ...
##  $ X3SsnPorch   : int  0 0 0 0 0 320 0 0 0 0 ...
##  $ ScreenPorch  : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ PoolArea     : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ PoolQC       : chr  NA NA NA NA ...
##  $ Fence        : chr  NA NA NA NA ...
##  $ MiscFeature  : chr  NA NA NA NA ...
##  $ MiscVal      : int  0 0 0 0 0 700 0 350 0 0 ...
##  $ MoSold       : int  2 5 9 2 12 10 8 11 4 1 ...
##  $ YrSold       : int  2008 2007 2008 2006 2008 2009 2007 2009 2008 2008 ...
##  $ SaleType     : chr  &quot;WD&quot; &quot;WD&quot; &quot;WD&quot; &quot;WD&quot; ...
##  $ SaleCondition: chr  &quot;Normal&quot; &quot;Normal&quot; &quot;Normal&quot; &quot;Abnorml&quot; ...
##  $ SalePrice    : int  208500 181500 223500 140000 250000 143000 307000 200000 129900 118000 ...</code></pre>
<p>Olhando a descrição dos dados, vi que em algumas variáveis foi atribuido NA quando o elemento não estava presente. Irei alterar para uma string, tornando assim as observações úteis para a análise.</p>
<pre class="r"><code>#Alley
dados$Alley[which(is.na(dados$Alley))] = &quot;Naa&quot;

#Basement
dados$BsmtQual[which(is.na(dados$BsmtQual))] = &quot;Nb&quot;
dados$BsmtCond[which(is.na(dados$BsmtCond))] = &quot;Nb&quot;
dados$BsmtExposure[which(is.na(dados$BsmtExposure))] = &quot;Nb&quot;
dados$BsmtFinType1[which(is.na(dados$BsmtFinType1))] = &quot;Nb&quot;
dados$BsmtFinType2[which(is.na(dados$BsmtFinType2))] = &quot;Nb&quot;

#Fireplace
dados$FireplaceQu[which(is.na(dados$FireplaceQu))] = &quot;Nf&quot;

#Garage
dados$GarageType[which(is.na(dados$GarageType))] = &quot;Ng&quot;
dados$GarageFinish[which(is.na(dados$GarageFinish))] = &quot;Ng&quot;
dados$GarageQual[which(is.na(dados$GarageQual))] = &quot;Ng&quot;
dados$GarageCond[which(is.na(dados$GarageCond))] = &quot;Ng&quot;

#Pool
dados$PoolQC[which(is.na(dados$PoolQC))] = &quot;Np&quot;

#Fence
dados$Fence[which(is.na(dados$Fence))] = &quot;Nf&quot;</code></pre>
<p>O mesmo foi feito com a variável que indica o ano de construção da garagem, então nestes casos irei atribuir 0.</p>
<pre class="r"><code>dados$GarageYrBlt[which(is.na(dados$GarageYrBlt))] = 0</code></pre>
<p>As variáveis que indicam a identificação da casa, o mês, ano, tipo e condições da venda não serão uteis para a análise, então irei removê-las.</p>
<pre class="r"><code>dados &lt;- dados %&gt;%
  select(-c(MoSold, YrSold, SaleType, SaleCondition, Id))</code></pre>
<p>E em algumas variáveis categoricas o nível foi descrito por um número, portanto será necessário converter para uma string.</p>
<pre class="r"><code>dados$MSSubClass = as.character(dados$MSSubClass)
dados$OverallQual = as.character(dados$OverallQual)
dados$OverallCond = as.character(dados$OverallCond)</code></pre>
<p>O gráfico abaixo mostra a porcentagem de NA’s em cada variável.</p>
<pre class="r"><code>gg_miss_var(dados, show_pct = T) +
  labs(x = &quot;Variáveis&quot;,y = &quot;Porcentagem de NA&quot;)</code></pre>
<p><img src="/post/2019-09-30-regress%C3%A3o-prevendo-o-pre%C3%A7o-de-casas_files/figure-html/unnamed-chunk-8-1.png" width="672" />
Irei remover a variável com mais de 20% de NA’s</p>
<pre class="r"><code>dados &lt;- dados %&gt;%
  select(-c(MiscFeature))</code></pre>
<p>e vou imputar a categoria mais frequente ou a mediana das observações, caso seja numérica, nas demais variáveis.</p>
<pre class="r"><code>#Convertendo as strings em fatores 
#Encontra as colunas que possuem string
ind &lt;- sapply(dados, is.character)
#Converte para fator
dados[ind] &lt;- lapply(dados[ind], factor)

#Imputando dados- para a categoria mais frequente ou para a mediana caso numerico
dados &lt;- na.roughfix(dados)</code></pre>
<p>E agora não há mais NA’s nos dados.</p>
<pre class="r"><code>gg_miss_var(dados, show_pct = T) +
  labs(x = &quot;Variáveis&quot;,y = &quot;Porcentagem de NA&quot;)</code></pre>
<img src="/post/2019-09-30-regress%C3%A3o-prevendo-o-pre%C3%A7o-de-casas_files/figure-html/unnamed-chunk-11-1.png" width="672" />
<h3>
Feature engineering
</h3>
<p>Aqui irei criar algumas novas variáveis e aplicar transformações onde necessário.</p>
<p>Para começar irei criar uma variável com o total de banheiros na casa</p>
<pre class="r"><code>dados &lt;- dados %&gt;%
  mutate(bathrooms = BsmtFullBath + 0.5*BsmtHalfBath + FullBath + 0.5*HalfBath) %&gt;%
  select(-c(BsmtFullBath, BsmtHalfBath, FullBath, HalfBath))</code></pre>
<p>e uma para a área total da casa.</p>
<pre class="r"><code>dados &lt;- dados %&gt;%
  mutate(TotalSF = X1stFlrSF + X2ndFlrSF + TotalBsmtSF) %&gt;%
  select(-c(X1stFlrSF, X2ndFlrSF, TotalBsmtSF))</code></pre>
<p>A distribuição da variável resposta SalePrice é bastante assimétrica à direita</p>
<pre class="r"><code>ggplot(dados, aes(x = SalePrice)) + 
  geom_density() + theme_bw()</code></pre>
<p><img src="/post/2019-09-30-regress%C3%A3o-prevendo-o-pre%C3%A7o-de-casas_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>e comparando os quantis da distribuição de SalePrice com os quantis teóricos da distribuição normal, podemos ver que a variável foge bastante da hipótese de normalidade.</p>
<pre class="r"><code>ggplot(dados, aes(sample = SalePrice)) +
  geom_qq() + geom_qq_line() + theme_bw()</code></pre>
<p><img src="/post/2019-09-30-regress%C3%A3o-prevendo-o-pre%C3%A7o-de-casas_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>O logaritmo natural parece amenizar bastante o problema da assimetria.</p>
<pre class="r"><code>ggplot(dados, aes(x = log(SalePrice))) + 
  geom_density() + theme_bw()</code></pre>
<p><img src="/post/2019-09-30-regress%C3%A3o-prevendo-o-pre%C3%A7o-de-casas_files/figure-html/unnamed-chunk-16-1.png" width="672" />
Mas apesar de estar bem mais próxima de uma gaussiana, a variável ainda não se adequa a distribuição normal, o que não é um problema para os métodos que irei utilizar.</p>
<pre class="r"><code>ggplot(dados, aes(sample = log(SalePrice))) + 
  geom_qq() + geom_qq_line() + theme_bw()</code></pre>
<p><img src="/post/2019-09-30-regress%C3%A3o-prevendo-o-pre%C3%A7o-de-casas_files/figure-html/unnamed-chunk-17-1.png" width="672" />
Portanto, manterei a transformação.</p>
<pre class="r"><code>dados &lt;- dados %&gt;%
  mutate(SalePrice = log(SalePrice))</code></pre>
<p>Abaixo é mostrado o coeficiente de assmimetria para as demais variáveis numéricas. Algumas delas possuem assimetrias bastante significativas e será necessário aplicar uma transformação para corrigir isto.</p>
<pre class="r"><code>psych::skew(select_if(dados, is.numeric))</code></pre>
<pre><code>##  [1]  2.4041986 12.1826150 -0.6122012 -0.5025278  2.6721170  1.6820413
##  [7]  4.2465214  0.9183784  8.9928333  1.3637536  0.2113551  4.4791783
## [13]  0.6749517  0.6482311 -3.8615534 -0.3418454  0.1796113  1.5382100
## [19]  2.3594857  3.0835258 10.2831784  4.1137473 14.7979183 24.4265224
## [25]  0.1210859  0.2641325  1.7730505</code></pre>
<p>Como essas variáveis possuem zeros ou valores negativos, não será possível aplicar o logaritmo natural como foi feito com SalePrice, então aplicarei a raiz cúbica de toda variável com assimetria menor que -0.75 ou maior que 0.75.</p>
<pre class="r"><code>ind &lt;- sapply(dados, is.numeric)
for(i in 1:ncol(dados)){
  if(ind[i]){
    if(psych::skew(dados[,i])&gt;0.75 | psych::skew(dados[,i]) &lt; -0.75){
      dados[,i] = (dados[,i])^(1/3)
    }
  }
}</code></pre>
<p>O que produziu bons resultados para a maioria dos casos.</p>
<pre class="r"><code>psych::skew(select_if(dados, is.numeric))</code></pre>
<pre><code>##  [1] -0.08708814  2.24511025 -0.61220121 -0.50252776  0.70529915
##  [6] -0.35450003  2.72602352 -1.00183220  7.70532558  0.38241571
## [11]  0.21135511  0.34503426  0.67495173  0.64823107 -3.87770277
## [16] -0.34184538  0.17961125  0.27269050  0.17711218  2.19119203
## [21]  7.90825015  3.21481019 14.37182501  6.45735540  0.12108586
## [26]  0.26413255  0.23135118</code></pre>
<p>Por fim ficamos com</p>
<pre class="r"><code>dim(dados)</code></pre>
<pre><code>## [1] 1460   70</code></pre>
<h2>
Modelagem
</h2>
<p>Para começar vou dividir os dados em um conjunto de treino, que corresponderá a 80% das observações, e um conjunto de validação com o restante e carregar os pacotes necessários nesta etapa.</p>
<pre class="r"><code>set.seed(576)
index = sample(1:dim(dados)[1], 1168, replace = F)
treino = dados[index,]
validacao = dados[-index,]</code></pre>
<pre class="r"><code>library(caret)
library(randomForest)
library(doMC)
library(gbm)
library(kernlab)</code></pre>
<p>Definindo o número de threads a ser utilizado.</p>
<pre class="r"><code>registerDoMC(cores = 4)</code></pre>
Em todos os casos será utilizada a validação cruzada repetida para definir a melhor combinação de hiperparâmetros. Por limitações de poder computacional nem sempre foi possível encontrar a combinação ótima dos hiperpârametros.
<h3>
Random Forest
</h3>
<p>Para começar irei fazer o tuning do parâmetro mtry do random forest, que representa o número de variáveis que participarão do sorteio na divisão de cada nó nas árvores.</p>
<pre class="r"><code>control &lt;- trainControl(method = &quot;repeatedcv&quot;, 
                      number = 10,
                      repeats = 3)

tunegrid &lt;- expand.grid(.mtry=seq(1,69,1))

model.rf.mtry = train(SalePrice~., data = treino, method = &quot;rf&quot;, tuneGrid=tunegrid, metric=&quot;RMSE&quot;, trControl=control)
model.rf.mtry</code></pre>
<pre><code>## Random Forest 
## 
## 1168 samples
##   69 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 1052, 1051, 1051, 1050, 1051, 1051, ... 
## Resampling results across tuning parameters:
## 
##   mtry  RMSE       Rsquared   MAE       
##    1    0.3071331  0.7810402  0.22607670
##    2    0.2254758  0.8143281  0.15783921
##    3    0.1936032  0.8364856  0.13249279
##    4    0.1776564  0.8510921  0.12025337
##    5    0.1681296  0.8607840  0.11323940
##    6    0.1627488  0.8660263  0.10935524
##    7    0.1589866  0.8691845  0.10647024
##    8    0.1557965  0.8725056  0.10420378
##    9    0.1532778  0.8753523  0.10258097
##   10    0.1518917  0.8763699  0.10152837
##   11    0.1501778  0.8782940  0.10051130
##   12    0.1494971  0.8784993  0.10016042
##   13    0.1480806  0.8800844  0.09900142
##   14    0.1476059  0.8802354  0.09867569
##   15    0.1465570  0.8812828  0.09809760
##   16    0.1459670  0.8818427  0.09761319
##   17    0.1450209  0.8827507  0.09696197
##   18    0.1448914  0.8828137  0.09707160
##   19    0.1443649  0.8832091  0.09661135
##   20    0.1435585  0.8842482  0.09592553
##   21    0.1437793  0.8834199  0.09623241
##   22    0.1431377  0.8838096  0.09572380
##   23    0.1425945  0.8845429  0.09538230
##   24    0.1425120  0.8847815  0.09551756
##   25    0.1421370  0.8851159  0.09536504
##   26    0.1422302  0.8846188  0.09531927
##   27    0.1415267  0.8856568  0.09494621
##   28    0.1415552  0.8852868  0.09478804
##   29    0.1412062  0.8856048  0.09469074
##   30    0.1410151  0.8859585  0.09450404
##   31    0.1410779  0.8855805  0.09470133
##   32    0.1409702  0.8854917  0.09438240
##   33    0.1414394  0.8845036  0.09451632
##   34    0.1407760  0.8855469  0.09448911
##   35    0.1405608  0.8856942  0.09432777
##   36    0.1401718  0.8862803  0.09419182
##   37    0.1406369  0.8852311  0.09425733
##   38    0.1406003  0.8851706  0.09423406
##   39    0.1401908  0.8856175  0.09409481
##   40    0.1402438  0.8854223  0.09413707
##   41    0.1401805  0.8855006  0.09398179
##   42    0.1401042  0.8855886  0.09413101
##   43    0.1402814  0.8850709  0.09417576
##   44    0.1404239  0.8849399  0.09444120
##   45    0.1395261  0.8862789  0.09381134
##   46    0.1397598  0.8857732  0.09388258
##   47    0.1397561  0.8856509  0.09394146
##   48    0.1397801  0.8855166  0.09393174
##   49    0.1394734  0.8859182  0.09375560
##   50    0.1399445  0.8849246  0.09416178
##   51    0.1394826  0.8858094  0.09398916
##   52    0.1402274  0.8844410  0.09420846
##   53    0.1397968  0.8852276  0.09417695
##   54    0.1393756  0.8856854  0.09374741
##   55    0.1397599  0.8848938  0.09407772
##   56    0.1395496  0.8853540  0.09412655
##   57    0.1395353  0.8853507  0.09399841
##   58    0.1395029  0.8851668  0.09377249
##   59    0.1393193  0.8853031  0.09380104
##   60    0.1394579  0.8852845  0.09402501
##   61    0.1393637  0.8852169  0.09376707
##   62    0.1396414  0.8847520  0.09406628
##   63    0.1395461  0.8847076  0.09405419
##   64    0.1397357  0.8844860  0.09415471
##   65    0.1396264  0.8846549  0.09398381
##   66    0.1395992  0.8846408  0.09412881
##   67    0.1395331  0.8846109  0.09396411
##   68    0.1392987  0.8848799  0.09394804
##   69    0.1394037  0.8847799  0.09394884
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was mtry = 68.</code></pre>
<p>Então o melhor valor de mtry é 68. Por fim farei uma busca pelo valor ótimo do número de árvores no modelo fixando o mtry como a raiz quadrada de 69, o número de variáveis.</p>
<pre class="r"><code>tunegrid &lt;- expand.grid(.mtry = sqrt(ncol(treino)))
modellist &lt;- list()

for (ntree in c(100,250,500,1000,1500,2000)){
  set.seed(250)
  fit &lt;- train(SalePrice~.,
               data = treino,
               method = &quot;rf&quot;,
               metric = &quot;RMSE&quot;,
               tuneGrid = tunegrid,
               trControl = control,
               ntree = ntree)
  key &lt;- toString(ntree)
  modellist[[key]] &lt;- fit
}
results &lt;- resamples(modellist)
dotplot(results)</code></pre>
<p><img src="/post/2019-09-30-regress%C3%A3o-prevendo-o-pre%C3%A7o-de-casas_files/figure-html/unnamed-chunk-29-1.png" width="672" />
O acréscimo no número de árvores não trouxe melhorias para o modelo, então pelo critério da parcimônia optarei o valor 100. Agora só resta ajustar o modelo final e calcular o RMSE.</p>
<pre class="r"><code>model.rf.final = randomForest(SalePrice~., data = treino, mtry = 68, ntree = 100)
rmse.rf.final = RMSE(exp(predict(model.rf.final,validacao)), exp(validacao$SalePrice))
rmse.rf.final</code></pre>
<pre><code>## [1] 29332.11</code></pre>
